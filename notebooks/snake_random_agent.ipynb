{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, go to the ple folder and find snake.py under games. Change the width and height to 600 in the Snake class (otherwise it's way too small). Then the following code should render the snake environment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os, sys\n",
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "import gym_ple\n",
    "\n",
    "# The world's simplest agent!\n",
    "class RandomAgent(object):\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def act(self, observation, reward, done):\n",
    "        return self.action_space.sample()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # You can optionally set up the logger. Also fine to set the level\n",
    "    # to logging.DEBUG or logging.WARN if you want to change the\n",
    "    # amount of output.\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    env = gym.make('Snake-v0')\n",
    "\n",
    "    # You provide the directory to write to (can be an existing\n",
    "    # directory, including one with existing data -- all monitor files\n",
    "    # will be namespaced). You can also dump to a tempdir if you'd\n",
    "    # like: tempfile.mkdtemp().\n",
    "    outdir = '/tmp/random-agent-results'\n",
    "    # env = Monitor(env, directory=outdir, force=True)\n",
    "\n",
    "    # This declaration must go *after* the monitor call, since the\n",
    "    # monitor's seeding creates a new action_space instance with the\n",
    "    # appropriate pseudorandom number generator.\n",
    "    env.seed(0)\n",
    "    agent = RandomAgent(env.action_space)\n",
    "\n",
    "    episode_count = 100\n",
    "    reward = 0\n",
    "    done = False\n",
    "\n",
    "    for i in range(episode_count):\n",
    "        ob = env.reset()\n",
    "\n",
    "        while True:\n",
    "            action = agent.act(ob, reward, done)\n",
    "            ob, reward, done, _ = env.step(action)\n",
    "            env.render()\n",
    "            if done:\n",
    "                break\n",
    "            # Note there's no env.render() here. But the environment still can open window and\n",
    "            # render if asked by env.monitor: it calls env.render('rgb_array') to record video.\n",
    "            # Video is not recorded every episode, see capped_cubic_video_schedule for details.\n",
    "\n",
    "    # Dump result info to disk\n",
    "    env.close()\n",
    "\n",
    "    # Upload to the scoreboard. We could also do this from another\n",
    "    # process if we wanted.\n",
    "    logger.info(\"Successfully ran RandomAgent. Now trying to upload results to the scoreboard. If it breaks, you can always just try re-uploading the same results.\")\n",
    "    gym.upload(outdir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
